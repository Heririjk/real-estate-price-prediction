{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver import Safari\n",
    "import pandas as pd\n",
    "from selenium.webdriver.common.by import By\n",
    "import requests\n",
    "import bs4\n",
    "drive = Safari(executable_path =r\"/usr/bin/safaridriver\")\n",
    "data = []\n",
    "time.sleep(5)\n",
    "for i in range(8,22,1):\n",
    "    try:\n",
    "        drive.get('https://www.immoweb.be/en/search/house/for-sale/brussels/district?countries=BE&maxPrice=500000&minPrice=200000'\n",
    "        + '&page='+str(i)+'&orderBy=relevance')\n",
    "        time.sleep(15)\n",
    "        soup = bs4.BeautifulSoup(drive.page_source, \"html.parser\")\n",
    "        jobs_elements = soup.find_all(\"h2\", class_= \"card__title card--result__title\")\n",
    "        for jobs_element in jobs_elements:\n",
    "            try:\n",
    "                table_data = jobs_element.find_all(\"a\", class_= 'card__title-link')\n",
    "                for var in table_data:\n",
    "                    item = var.get('href')\n",
    "            except AttributeError:\n",
    "                table_data = 'no data'\n",
    "            data.append(item)\n",
    "        time.sleep(15)\n",
    "    except:\n",
    "        continue\n",
    "with open('links_6.txt',\"w\") as f:\n",
    "    for x in data:\n",
    "        f.write(x+'\\n')\n",
    "with open('links_6.txt',\"r\") as r:\n",
    "    array = r.read().splitlines()\n",
    "    print(array)\n",
    "drive.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "import bs4\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver import Safari\n",
    "import pandas as pd\n",
    "import threading\n",
    "import numpy as np\n",
    "dict = { 'ID':[], 'Locality':[],'PricePr': [], 'Tenement building':[],'Venue of the sale':[],\n",
    "      'Bedrooms':[],  \"Living area\":[], \"Kitchen type\":[], \"Furnished\" : [] , 'How many fireplaces?':[], 'Terrace':[], 'Terrace surface':[], \n",
    "       'Garden':[], 'Garden surface':[], 'Surface of the plot':[], 'Number of frontages': [], 'Swimming pool':[], 'Building condition':[]}\n",
    "data_columns = list(dict.keys())\n",
    "drive = Safari(executable_path=r\"/usr/bin/safaridriver\")\n",
    "with open(\"data/links_0.txt\") as f:\n",
    "    links = f.read().split(\"\\n\")\n",
    "    for var in links:\n",
    "        try:\n",
    "            \n",
    "            thread = threading.Thread(target=drive.get(url = var))\n",
    "            soup = bs4.BeautifulSoup(drive.page_source, \"html.parser\") \n",
    "            table_datas = soup.find_all(\"tr\", class_= \"classified-table__row\")\n",
    "            thread.start()\n",
    "            sleep(3)\n",
    "            headers = []\n",
    "            dict['ID'].append(var.rsplit('/', 1)[1])\n",
    "            headers.append('ID')\n",
    "            dict['Locality'].append(var.rsplit('/')[-3])\n",
    "            headers.append('Locality')\n",
    "            price = soup.find('p', class_='classified__price').find('span', class_='sr-only').string\n",
    "            dict[\"PricePr\"].append(price)\n",
    "            headers.append('PricePr')\n",
    "            for x in table_datas:\n",
    "                try:\n",
    "                    table_data = x.find(\"td\", class_=\"classified-table__data\").text.strip()\n",
    "                    table_data = table_data.replace('square meters', '').replace('mÂ²', '').replace('m', '').strip(\"\\n\").strip(\"\\t\").strip()\n",
    "                except AttributeError:\n",
    "                    table_data = np.NaN\n",
    "                try:\n",
    "                    table_header = x.find(\"th\", class_=\"classified-table__header\").text.strip()\n",
    "                    headers.append(table_header)\n",
    "                except AttributeError:\n",
    "                    table_header = np.NaN\n",
    "                \n",
    "                if table_header == 'Tenement building':\n",
    "                    dict[\"Tenement building\"].append(table_data)\n",
    "                if table_header == 'Venue of the sale':\n",
    "                    dict[\"Venue of the sale\"].append(table_data)\n",
    "                if table_header == 'Living area':\n",
    "                    dict[\"Living area\"].append(table_data)\n",
    "                if table_header == 'Kitchen type':\n",
    "                    dict[\"Kitchen type\"].append(table_data)\n",
    "                if table_header =='Bedrooms':\n",
    "                    dict[\"Bedrooms\"].append(table_data)\n",
    "                if table_header == 'Surface of the plot':\n",
    "                    dict[\"Surface of the plot\"].append(table_data)\n",
    "                if table_header == 'Terrace':\n",
    "                    dict[\"Terrace\"].append(table_data)\n",
    "                if table_header == 'Terrace surface':\n",
    "                    dict[\"Terrace surface\"].append(table_data)\n",
    "                if table_header == 'Garden surface':\n",
    "                    dict[\"Garden surface\"].append(table_data)\n",
    "                if table_header == 'Garden':\n",
    "                    dict[\"Garden\"].append(table_data)\n",
    "                if table_header == 'Furnished':\n",
    "                    dict[\"Furnished\"].append(table_data)\n",
    "                if table_header == 'How many fireplaces?':\n",
    "                    dict[\"How many fireplaces?\"].append(table_data)\n",
    "                if table_header == 'Number of frontages':\n",
    "                    dict[\"Number of frontages\"].append(table_data)\n",
    "                if table_header == 'Swimming pool':\n",
    "                    dict[\"Swimming pool\"].append(table_data)\n",
    "                if table_header == 'Building condition':\n",
    "                    dict[\"Building condition\"].append(table_data)\n",
    "            diff = list(set(data_columns)-set(headers))\n",
    "            for y in diff:\n",
    "                dict[y].append(np.NaN)\n",
    "            sleep(3) \n",
    "            thread.join()\n",
    "        except TimeoutError:\n",
    "            print('This is TimeoutError')\n",
    "        except:\n",
    "            break\n",
    "\n",
    "new_dict = pd.DataFrame(dict)\n",
    "with open('page_2.csv',\"w\") as f:\n",
    "    new_dict.to_csv('page_2.csv', index=False)\n",
    "drive.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('page_2.csv',\"r\") as f:\n",
    "    df=pd.read_csv('page_2.csv')\n",
    "#code to add new column bv. to fill null values with Brussel\n",
    "#df['Neighbourhood or locality'] = df['Neighbourhood or locality'].fillna('Brussel')\n",
    "print(df)\n",
    "with open('page_2.csv',\"w\") as f:\n",
    "    df.to_csv('page_2.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
